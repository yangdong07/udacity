
## 我在此确认，所提交的项目为我的工作成果，其中引用的信息出自网站、书籍、论坛、博客文章和 GitHub 代码库等

## 1. 向我们总结此项目的目标以及机器学习对于实现此目标有何帮助。作为答案的部分，提供一些数据集背景信息以及这些信息如何用于回答项目问题。你在获得数据时它们是否包含任何异常值，你是如何进行处理的？【相关标准项：“数据探索”，“异常值调查”】

安然曾是 2000 年美国最大的公司之一。2002 年，由于其存在大量的企业欺诈行为，这个昔日的大集团土崩瓦解。 在随后联邦进行的调查过程中，大量有代表性的保密信息进入了公众的视线，包括成千上万涉及高管的邮件和详细的财务数据。

本项目目的是根据安然数据集（邮件及财务数据）以及涉案人员标签（POI）使用机器学习算法训练模型，该模型可以从根据人员信息较准确的预测出是否为涉案人员。

这份数据共有146条记录，每条记录据包含20个特征（feature）。这20个特征多少都有缺失（NaN值），这些值有些可能本身就为0，也有些确实是缺失，信息不完整，例如没有email_address的，相应的email的统计信息基本上都是NaN。email数据中只有86条记录有email地址，没有缺失数据。

财务信息中loan_advances只有4条记录有具体值，但这些财务数据的缺失值均可以认为是0。 

数据包含部分异常值。

    a. TOTAL数据 是表格统计信息，并不是个人信息。数据处理时，丢弃该行数据
    b. BELFER ROBERT  和 BHATNAGAR SANJAY 两人的数据记录有误，似乎是错列记录了。
    c. LOCKHART EUGENE E 的所有特征均为NaN，没有有用信息，可以删掉。

对于邮件数据的NaN值，这些数据信息属于未知（unknown）信息。 DecisionTree算法可以处理未知数据。简单起见，我在这里将所有NaN值均填充为0。


## 2. 你最终在你的 POI 标识符中使用了什么特征，你使用了什么筛选过程来挑选它们？你是否需要进行任何缩放？为什么？作为任务的一部分，你应该尝试设计自己的特征，而非使用数据集中现成的——解释你尝试创建的特征及其基本原理。（你不一定要在最后的分析中使用它，而只设计并测试它）。在你的特征选择步骤，如果你使用了算法（如决策树），请也给出所使用特征的特征重要性；如果你使用了自动特征选择函数（如 SelectBest），请报告特征得分及你所选的参数值的原因。【相关标准项：“创建新特征”、“适当缩放特征”、“智能选择功能”】


### 创建新特征
在特征选择时，首先只考虑财务数据，得出来的评分较低；

然后考虑全部特征，可以提升一些评分，但是效果不明显。

尝试添加新的特征。主要考虑一些比例关系。比如，因为有 from_this_person_to_poi 和 from_messages， 数量绝对值可能不会集中分布。但是如果考虑 二者比例，即 发送给poi邮件的占总发送邮件的占比，那么可以假设认为，这个比例数值偏高的，也是poi。这样就加入了可能的模式在里面。

同理还考虑： from_poi_to_this_person 与 to_messages 之比， shared_receipt_with_poi 与 to_messages 之比。

财务信息也应当是评估poi的重要特征，但是原始数据只罗列了一些基本信息。同样考虑一些比例：  bonus 与salary之比，是不是存在特定模式？
total_payments 和 total_stock_value呢？

在加入这些特征之后，只使用默认的算法，就可以得到较好的结果。

### 适当缩放特征

SVC算法需要计算空间距离，最好还是对特征进行缩放。 项目中实际操作了特征缩放，能提升评分，但是没有达到项目要求。


### 特征选择
(见 EnronData.html中特征选择操作，在poi_id中使用了全部特征，并没有进行选择)
在使用DecisionTree算法训练模型时，可以得出各个特征重要性的度量（feature_importances_）
```
[('exercised_stock_options', 0.22600000000000023),
 ('payments_to_stock', 0.14828456020380801),
 ('bonus', 0.12810523836079463),
 ('shared_poi_ratio', 0.12610474109558947),
 ('to_poi_ratio', 0.12451869894486046),
 ('bonus_to_salary', 0.087052558429770832),
 ('salary', 0.053512168141592924),
 ('restricted_stock', 0.041018273761636595),
 ('deferral_payments', 0.035674778761061954),
 ('shared_receipt_with_poi', 0.029728982300884967),
 ('long_term_incentive', 0.0),
 ('deferred_income', 0.0),
 ('loan_advances', 0.0),
 ('other', 0.0),
 ('expenses', 0.0),
 ('director_fees', 0.0),
 ('total_payments', 0.0),
 ('restricted_stock_deferred', 0.0),
 ('total_stock_value', 0.0),
 ('from_messages', 0.0),
 ('from_poi_to_this_person', 0.0),
 ('from_this_person_to_poi', 0.0),
 ('to_messages', 0.0),
 ('from_poi_ratio', 0.0)]
```
 虽然这种顺序是随机的，但是对于部分特征来说还是有意义的，比如 payments_to_stock、bonus、shared_poi_ratio、to_poi_ratio、bonus_to_salary等，这些多数是新定义的特征。从算法角度，说明可以从这些特征中找出模式，得到更好的模型。
 
 接下来，截取了这些非零权重的特征进行训练，得出来的结果并没有变坏，说明了可以只使用这些主要特征进行训练，可以提升训练速度。


## 3.	你最终使用了什么算法？你还尝试了其他什么算法？不同算法之间的模型性能有何差异？【相关标准项：“选择算法”】

尝试了 GaussianNB、SVC、DecisionTree、AdaBoost算法，最终选择了AdaBoost算法。

GaussianNB 是混合模型算法，只是根据数据的分布（高斯分布）模型对数据进行分类。算法的特点是速度较快，但是对于相当少的数据量来说，训练效果并不好。

SVC算法尝试寻找数据分类的最佳边界，是很优秀的算法。对大数据来说速度较慢。这里对少量数据而言，训练评分可以达到最高 1，但是测试集评分确实最低，很明显是产生了过拟合。此外，SVC算法需要计算空间距离，对特征取值范围有要求，需要进行特征缩放。

DecisionTree 是根据特征取值，分割数据并对数据进行分类。算法简单且有效，并且可以评估特征的重要性。

AdaBoost 算法的思想是将简单的分类器组合起来得到一个强大的分类器。AdaBoost的一个优点是，不容易产生过拟合现象，对于测试集的表现也比较好。


## 4.	调整算法的参数是什么意思，如果你不这样做会发生什么？你是如何调整特定算法的参数的？（一些算法没有需要调整的参数 – 如果你选择的算法是这种情况，指明并简要解释对于你最终未选择的模型或需要参数调整的不同模型，例如决策树分类器，你会怎么做）。【相关标准项：“调整算法”】

机器学习算法除了学习到的模型参数之外，还有超参需要调整，这些超参影响着模型的性能：训练速度、收敛性、是否产生过拟合等等。

如果不调整算法的参数（超参），就不能了解模型是否最优模型，是否产生过拟合等。

使用了GridSearchCV 使用超参字典和交叉验证集合来调整参数，选择最优模型。


## 5.	什么是验证，未正确执行情况下的典型错误是什么？你是如何验证你的分析的？【相关标准项：“验证策略”】

validation 是用于训练时评估模型，其目的是选择合适的算法参数，得到最优模型。

首先，不能使用训练使用的数据来评估模型，因为算法训练结果是对训练数据优化的，并不能代表一般结果；

其次，也不能用测试数据来进行验证。这样训练出来的模型及其参数，也是对测试数据经过优化了的。（这也是典型错误之一）

在实际操作中，将数据划分成 训练数据和测试数据集， 然后将训练数据取出一部分作为验证数据。 可以将训练数据分成若干份，每次训练取出一份作为验证集，其余用来训练模型，用验证集评估模型，这就是交叉验证。如果将数据均分为K份进行交叉验证，称为K-Fold交叉验证，GridSearchCV参数中的cv 默认指 K-fold交叉验证的份数。 对于不平衡的分类数据，可以使用 StratifiedKFold 或 StratifiedShuffleSplit 划分训练数据集。 在使用GridSearchCV 对决策树算法进行网格搜索时，定义参数 `cv = StratifiedKFold(10)` 对训练集进行划分。（见EnronData.html）

在测试代码中，使用StratifiedShuffleSplit 对全部数据进行了1000次划分，每次划分使用训练集训练，测试集评分，最终计算出平均值，即模型的最终评分。


## 6.	给出至少 2 个评估度量并说明每个的平均性能。解释对用简单的语言表明算法性能的度量的解读。【相关标准项：“评估度量的使用”】

accuracy，准确度，是指预测正确的占所有预测数量的比值。对一般分类器，accuracy可以很好评估模型。但是对于偏斜分类的数据，比如Enron数据问题，只有12.3%的人为POI，对一个将所有人预测为非POI的分类器来说，其准确度就可以达到87.7%。所以在这个问题中， accuracy不是一个好的性能度量。

precision，精确度，指所有为正的预测中，正确的预测所占的比例。在这个问题中，为正的预测指预测结果为POI。最后得到的precision平均值为 45.5%。其意义是，使用算法预测100个人为POI，其中只有45.5% 是正确预测的，即真正的POI，其余都是错误的预测。

recall，召回率，指所有为正的数据，其预测结果也为正的比例。这里为正的数据是指本身为POI的人员，最后正确预测为POI的比例是 33.6%。其意义是，使用算法可以正确预测出100个POI中的 33.6% 个。其余的就漏掉了。

f1_score，是precision和recall的调和平均数。 在算法训练时，使用这个数作为算法性能的度量。提高f1_score的目的也可以同时提高precision和recall。

在实际应用中，还需要看precision和recall哪个最重要。如果希望宁可错杀一千，不可放过一个，就是提高recall，可以牺牲precision。如果希望谨慎用事，对漏掉的并不在意，就可以选择提高precision。


