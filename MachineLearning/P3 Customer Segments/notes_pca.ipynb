{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PCA notes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import visuals as vs\n",
    "from IPython.display import display # 使得我们可以对DataFrame使用display()函数\n",
    "\n",
    "# 设置以内联的形式显示matplotlib绘制的图片（在notebook中显示更美观）\n",
    "%matplotlib inline\n",
    "\n",
    "# 载入整个客户数据集\n",
    "try:\n",
    "    data = pd.read_csv(\"customers.csv\")\n",
    "    data.drop(['Region', 'Channel'], axis = 1, inplace = True)\n",
    "except:\n",
    "    print (\"Dataset could not be loaded. Is the dataset missing?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(435, 6)\n"
     ]
    }
   ],
   "source": [
    "# 特征缩放\n",
    "log_data = np.log(data)\n",
    "\n",
    "# 清理异常值： 定义为多于一个维度中， 位于 [Q1 - 1.5IQR, Q3 + 1.5IQR] 范围外的点\n",
    "outliers  = []\n",
    "for feature in log_data.keys():\n",
    "    Q1 = np.percentile(log_data[feature], 25)\n",
    "    Q3 = np.percentile(log_data[feature], 75)\n",
    "    IQR = Q3 - Q1\n",
    "    outlier_data = log_data[~((log_data[feature] >= Q1 - 1.5 * IQR) & (log_data[feature] <= Q3 + 1.5 * IQR))]\n",
    "    outliers.extend(outlier_data.index.values)\n",
    "\n",
    "from collections import Counter\n",
    "counter = Counter(outliers)\n",
    "# 多于一个特征下被看作是异常的数据点\n",
    "outliers2 = [k for k in counter.keys() if counter[k] > 1]\n",
    "# display(data.iloc[outliers2])\n",
    "\n",
    "good_data = log_data.drop(log_data.index[outliers2]).reset_index(drop = True)\n",
    "print(good_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA (mannually)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6, 435)\n"
     ]
    }
   ],
   "source": [
    "# 转成np matrix\n",
    "test_data = good_data.as_matrix().transpose()   # D x N\n",
    "\n",
    "def normalize_data(d):\n",
    "    n, m = d.shape\n",
    "    mean = np.mean(d, axis=1, keepdims=True)\n",
    "    var = np.var(d, axis=1, keepdims=True)\n",
    "    return (d - mean) / np.sqrt(var)\n",
    "\n",
    "# test_data = normalize_data(test_data)\n",
    "print(test_data.shape)\n",
    "\n",
    "# set numpy print precision，Small results can be suppressed\n",
    "np.set_printoptions(precision=4, suppress=True)  # default: percision=8, suppress=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 2.0253 -0.0365 -0.1929  0.6295 -0.3572  0.3814]\n",
      " [-0.0365  1.1298  0.8662 -0.0864  1.2041  0.445 ]\n",
      " [-0.1929  0.8662  1.0943 -0.2239  1.3929  0.3128]\n",
      " [ 0.6295 -0.0864 -0.2239  1.5902 -0.4564  0.3595]\n",
      " [-0.3572  1.2041  1.3929 -0.4564  2.8377  0.3402]\n",
      " [ 0.3814  0.445   0.3128  0.3595  0.3402  1.5903]]\n",
      "[[ 1.     -0.0241 -0.1296  0.3507 -0.149   0.2125]\n",
      " [-0.0241  1.      0.779  -0.0645  0.6725  0.332 ]\n",
      " [-0.1296  0.779   1.     -0.1697  0.7904  0.2371]\n",
      " [ 0.3507 -0.0645 -0.1697  1.     -0.2148  0.2261]\n",
      " [-0.149   0.6725  0.7904 -0.2148  1.      0.1601]\n",
      " [ 0.2125  0.332   0.2371  0.2261  0.1601  1.    ]]\n"
     ]
    }
   ],
   "source": [
    "# PCA分析\n",
    "# 1.计算样本协方差矩阵\n",
    "n, m = test_data.shape\n",
    "\n",
    "def covariance_(a, b):\n",
    "    n, m = a.shape\n",
    "    assert((n, m) == b.shape)\n",
    "    mean_a = np.mean(a, axis=1, keepdims=True)\n",
    "    mean_b = np.mean(b, axis=1, keepdims=True)\n",
    "    return np.dot(a - mean_a, (b - mean_b).transpose()) / (m - 1)\n",
    "\n",
    "def variance_(d):\n",
    "    n, m = d.shape\n",
    "    mean = np.mean(d, axis=1, keepdims=True)\n",
    "    # print(mean)\n",
    "    return np.dot(d - mean, (d - mean).transpose()) / (m - 1)\n",
    "\n",
    "def correlation_(a, b):\n",
    "    cov = covariance_(a, b)\n",
    "    var_a = variance_(a)\n",
    "    var_b = variance_(b)\n",
    "    n = cov.shape[0]\n",
    "    cor = np.zeros(cov.shape)\n",
    "    for i in range(n):\n",
    "        for j in range(n):\n",
    "            cor[i][j] = cov[i][j] / np.sqrt(var_a[i][i] * var_b[j][j])\n",
    "    return cor\n",
    "\n",
    "covariance = np.cov(test_data)   # D x D\n",
    "print(covariance)\n",
    "correlation = np.corrcoef(test_data)  # D x D\n",
    "print(correlation)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eigenvalues:\n",
      " [ 4.5488  2.7085  1.2636  1.0392  0.498   0.2095]\n",
      "eigenvectors:\n",
      " [[-0.1675  0.6859  0.6774  0.2043 -0.0026  0.0292]\n",
      " [ 0.4014  0.1672 -0.0402 -0.0128  0.7192 -0.5402]\n",
      " [ 0.4381  0.0707  0.0195 -0.0557  0.3554  0.8205]\n",
      " [-0.1782  0.5005 -0.315  -0.7854 -0.0331  0.0205]\n",
      " [ 0.7514  0.0424  0.2117 -0.2096 -0.5582 -0.1824]\n",
      " [ 0.1499  0.4941 -0.6286  0.5423 -0.2092  0.0197]]\n",
      "Av:\n",
      " [[-0.7618  1.8579  0.8559  0.2123 -0.0013  0.0061]\n",
      " [ 1.8261  0.4529 -0.0508 -0.0133  0.3582 -0.1132]\n",
      " [ 1.9929  0.1916  0.0247 -0.0579  0.177   0.1719]\n",
      " [-0.8106  1.3557 -0.3981 -0.8162 -0.0165  0.0043]\n",
      " [ 3.4181  0.115   0.2675 -0.2178 -0.278  -0.0382]\n",
      " [ 0.6817  1.3384 -0.7942  0.5636 -0.1042  0.0041]]\n",
      "lv:\n",
      " [[-0.7618  1.8579  0.8559  0.2123 -0.0013  0.0061]\n",
      " [ 1.8261  0.4529 -0.0508 -0.0133  0.3582 -0.1132]\n",
      " [ 1.9929  0.1916  0.0247 -0.0579  0.177   0.1719]\n",
      " [-0.8106  1.3557 -0.3981 -0.8162 -0.0165  0.0043]\n",
      " [ 3.4181  0.115   0.2675 -0.2178 -0.278  -0.0382]\n",
      " [ 0.6817  1.3384 -0.7942  0.5636 -0.1042  0.0041]]\n",
      "v[0]:\n",
      " [-0.1675  0.4014  0.4381 -0.1782  0.7514  0.1499]\n",
      "Av[0]:\n",
      " [-0.7618  1.8261  1.9929 -0.8106  3.4181  0.6817]\n"
     ]
    }
   ],
   "source": [
    "# 2.计算 covariance矩阵 特征值，特征向量，排序，做一些验证\n",
    "eigenvalues, eigenvectors = np.linalg.eig(covariance)\n",
    "sorted_indices = np.argsort(eigenvalues)[::-1]   # 降序排序\n",
    "\n",
    "eigenvalues = eigenvalues[sorted_indices]\n",
    "eigenvectors = eigenvectors[:, sorted_indices]\n",
    "print('eigenvalues:\\n', eigenvalues)\n",
    "print('eigenvectors:\\n', eigenvectors)\n",
    "\n",
    "print('Av:\\n', np.dot(covariance, eigenvectors))\n",
    "print('lv:\\n', eigenvalues * eigenvectors)\n",
    "\n",
    "print('v[0]:\\n', eigenvectors[:, 0])    # v 是列向量\n",
    "print('Av[0]:\\n', np.dot(covariance, eigenvectors[:, 0]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$Av = lv$，  $l$是特征值，$v$是特征向量\n",
    "\n",
    "下面验证： $A = E^T \\Lambda E$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "covariance:\n",
      " [[ 2.0253 -0.0365 -0.1929  0.6295 -0.3572  0.3814]\n",
      " [-0.0365  1.1298  0.8662 -0.0864  1.2041  0.445 ]\n",
      " [-0.1929  0.8662  1.0943 -0.2239  1.3929  0.3128]\n",
      " [ 0.6295 -0.0864 -0.2239  1.5902 -0.4564  0.3595]\n",
      " [-0.3572  1.2041  1.3929 -0.4564  2.8377  0.3402]\n",
      " [ 0.3814  0.445   0.3128  0.3595  0.3402  1.5903]]\n",
      "digonal matrix:\n",
      " [[ 4.5488  0.      0.      0.      0.      0.    ]\n",
      " [ 0.      2.7085  0.      0.      0.      0.    ]\n",
      " [ 0.      0.      1.2636  0.      0.      0.    ]\n",
      " [ 0.      0.      0.      1.0392  0.      0.    ]\n",
      " [ 0.      0.      0.      0.      0.498   0.    ]\n",
      " [ 0.      0.      0.      0.      0.      0.2095]]\n",
      "decomposition:\n",
      " [[ 2.0253 -0.0365 -0.1929  0.6295 -0.3572  0.3814]\n",
      " [-0.0365  1.1298  0.8662 -0.0864  1.2041  0.445 ]\n",
      " [-0.1929  0.8662  1.0943 -0.2239  1.3929  0.3128]\n",
      " [ 0.6295 -0.0864 -0.2239  1.5902 -0.4564  0.3595]\n",
      " [-0.3572  1.2041  1.3929 -0.4564  2.8377  0.3402]\n",
      " [ 0.3814  0.445   0.3128  0.3595  0.3402  1.5903]]\n"
     ]
    }
   ],
   "source": [
    "print('covariance:\\n', covariance)\n",
    "print('digonal matrix:\\n', eigenvalues * np.identity(n))\n",
    "print('decomposition:\\n', np.dot(np.dot(eigenvectors, eigenvalues * np.identity(n)), eigenvectors.transpose()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6, 435)\n",
      "covariance matrix of transform_data:\n",
      " [[ 4.5488 -0.      0.      0.     -0.      0.    ]\n",
      " [-0.      2.7085  0.      0.      0.     -0.    ]\n",
      " [ 0.      0.      1.2636 -0.     -0.     -0.    ]\n",
      " [ 0.      0.     -0.      1.0392 -0.      0.    ]\n",
      " [-0.      0.     -0.     -0.      0.498  -0.    ]\n",
      " [ 0.     -0.     -0.      0.     -0.      0.2095]]\n"
     ]
    }
   ],
   "source": [
    "# 3.计算转换的数据，计算协方差矩阵，应当是特征值对角矩阵\n",
    "\n",
    "transform_data = np.dot(eigenvectors.transpose(), test_data)\n",
    "print(transform_data.shape)\n",
    "print('covariance matrix of transform_data:\\n', np.cov(transform_data))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$ND = E^T D$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eigenvectors(PC transform matrix):\n",
      " [[-0.1675  0.6859  0.6774  0.2043 -0.0026  0.0292]\n",
      " [ 0.4014  0.1672 -0.0402 -0.0128  0.7192 -0.5402]\n",
      " [ 0.4381  0.0707  0.0195 -0.0557  0.3554  0.8205]\n",
      " [-0.1782  0.5005 -0.315  -0.7854 -0.0331  0.0205]\n",
      " [ 0.7514  0.0424  0.2117 -0.2096 -0.5582 -0.1824]\n",
      " [ 0.1499  0.4941 -0.6286  0.5423 -0.2092  0.0197]]\n",
      "covariance of PC and origin variables:\n",
      " [[-0.7618  1.8579  0.8559  0.2123 -0.0013  0.0061]\n",
      " [ 1.8261  0.4529 -0.0508 -0.0133  0.3582 -0.1132]\n",
      " [ 1.9929  0.1916  0.0247 -0.0579  0.177   0.1719]\n",
      " [-0.8106  1.3557 -0.3981 -0.8162 -0.0165  0.0043]\n",
      " [ 3.4181  0.115   0.2675 -0.2178 -0.278  -0.0382]\n",
      " [ 0.6817  1.3384 -0.7942  0.5636 -0.1042  0.0041]]\n",
      "correlation of PC and origin variables:\n",
      " [[-0.251   0.7932  0.535   0.1463 -0.0013  0.0094]\n",
      " [ 0.8055  0.2589 -0.0425 -0.0123  0.4775 -0.2326]\n",
      " [ 0.8932  0.1113  0.021  -0.0543  0.2397  0.3591]\n",
      " [-0.3014  0.6533 -0.2808 -0.6349 -0.0185  0.0075]\n",
      " [ 0.9514  0.0415  0.1413 -0.1268 -0.2338 -0.0496]\n",
      " [ 0.2535  0.6449 -0.5603  0.4384 -0.1171  0.0072]]\n",
      "correlation of origin variables:\n",
      " [[ 1.     -0.0241 -0.1296  0.3507 -0.149   0.2125]\n",
      " [-0.0241  1.      0.779  -0.0645  0.6725  0.332 ]\n",
      " [-0.1296  0.779   1.     -0.1697  0.7904  0.2371]\n",
      " [ 0.3507 -0.0645 -0.1697  1.     -0.2148  0.2261]\n",
      " [-0.149   0.6725  0.7904 -0.2148  1.      0.1601]\n",
      " [ 0.2125  0.332   0.2371  0.2261  0.1601  1.    ]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 4.计算转换后的数据与原始数据变量之间的相关系数 (PCA讲义上用这个分析相关性，但是感觉没什么用)\n",
    "\n",
    "print('eigenvectors(PC transform matrix):\\n', eigenvectors)   # e1: eigenvectors[:, 0], 第一列的\n",
    "cov_yx = covariance_(transform_data, test_data)\n",
    "\n",
    "print('covariance of PC and origin variables:\\n', covariance_(transform_data, test_data).transpose())\n",
    "# print('calc: covariance of components and origin variables:\\n', np.dot(eigenvectors, eigenvalues * np.identity(n)))\n",
    "print('correlation of PC and origin variables:\\n', correlation_(transform_data, test_data).transpose())\n",
    "# print('correlation of components and origin variables:\\n', np.corrcoef(transform_data, test_data).transpose())\n",
    "print('correlation of origin variables:\\n', correlation_(test_data, test_data).transpose())\n",
    "\n",
    "# print('calc:\\n', np.dot(eigenvalues * np.identity(n), eigenvectors.transpose()))\n",
    "\n",
    "## normalize 之后再计算一遍， PCA 不用correlation， 而是用covariance， 为什么？\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[PCA讲义](https://onlinecourses.science.psu.edu/stat505/node/54) 分析了PC和原变量之间的相关系数， 其实可以看出来，第一个PC和 X2、X3、X5 即Milk、Grocery、Detergents_Paper 的相关系数都超过0.8。转换系数（即e1）分别是0.4， 0.43、0.75。 \n",
    "\n",
    "这个说明 PC1 具有同时购买X2、X3、X5的行为。 PC1 并不能表示某种类型的客户， 但是可以表示某种内在的行为联系： 如果购买X2，有很大可能同时购买X3、X5。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pca.explained_variance_:\n",
      " [ 4.5384  2.7023  1.2607  1.0368  0.4969  0.2091]\n",
      "eigenvalues:\n",
      " [ 4.5488  2.7085  1.2636  1.0392  0.498   0.2095]\n",
      "pca.components_:\n",
      " [[ 0.1675 -0.6859 -0.6774 -0.2043 -0.0026  0.0292]\n",
      " [-0.4014 -0.1672  0.0402  0.0128  0.7192 -0.5402]\n",
      " [-0.4381 -0.0707 -0.0195  0.0557  0.3554  0.8205]\n",
      " [ 0.1782 -0.5005  0.315   0.7854 -0.0331  0.0205]\n",
      " [-0.7514 -0.0424 -0.2117  0.2096 -0.5582 -0.1824]\n",
      " [-0.1499 -0.4941  0.6286 -0.5423 -0.2092  0.0197]]\n",
      "eigenvectors:\n",
      " [[-0.1675  0.6859  0.6774  0.2043 -0.0026  0.0292]\n",
      " [ 0.4014  0.1672 -0.0402 -0.0128  0.7192 -0.5402]\n",
      " [ 0.4381  0.0707  0.0195 -0.0557  0.3554  0.8205]\n",
      " [-0.1782  0.5005 -0.315  -0.7854 -0.0331  0.0205]\n",
      " [ 0.7514  0.0424  0.2117 -0.2096 -0.5582 -0.1824]\n",
      " [ 0.1499  0.4941 -0.6286  0.5423 -0.2092  0.0197]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 5.与sklearn的PCA比较\n",
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=6).fit(good_data)\n",
    "\n",
    "# # TODO：使用上面的PCA拟合将变换施加在log_samples上\n",
    "# pca_samples = pca.transform(log_samples)\n",
    "\n",
    "print('pca.explained_variance_:\\n', pca.explained_variance_)\n",
    "print('eigenvalues:\\n', eigenvalues)\n",
    "\n",
    "print('pca.components_:\\n', pca.components_.transpose())\n",
    "print('eigenvectors:\\n', eigenvectors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "数值居然对不上。。。。。\n",
    "eigentvectors和 pca大致相同， 符号除了最后一个，其他都是相反的。 特征向量符号相反不影响。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.758 ,  0.0097, -0.959 , -1.6824,  0.268 , -0.3891],\n",
       "       [-1.7887, -0.8123,  0.2315, -0.0036,  0.1194, -0.2106],\n",
       "       [-1.8834, -1.5991,  1.3204, -0.5432, -0.3934, -0.3117],\n",
       "       ..., \n",
       "       [-3.7425, -0.8561, -0.9885, -0.8879,  0.0503,  0.2058],\n",
       "       [ 1.6691, -0.398 ,  0.5161, -1.3189,  0.0913,  0.0056],\n",
       "       [ 0.739 ,  3.6914, -2.0335, -0.9927,  0.3109, -0.1734]])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca.transform(good_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.758 , -0.0097,  0.959 ,  1.6824,  0.268 , -0.3891],\n",
       "       [ 1.7887,  0.8123, -0.2315,  0.0036,  0.1194, -0.2106],\n",
       "       [ 1.8834,  1.5991, -1.3204,  0.5432, -0.3934, -0.3117],\n",
       "       ..., \n",
       "       [ 3.7425,  0.8561,  0.9885,  0.8879,  0.0503,  0.2058],\n",
       "       [-1.6691,  0.398 , -0.5161,  1.3189,  0.0913,  0.0056],\n",
       "       [-0.739 , -3.6914,  2.0335,  0.9927,  0.3109, -0.1734]])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.dot(eigenvectors.transpose(), test_data - np.mean(test_data, axis=1, keepdims=True)).transpose()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在做PCA转换时， 将坐标中心位置做了一次平移。 转换后的数据的均值为坐标原点\n",
    "\n",
    "还是有符号差异。。。"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
